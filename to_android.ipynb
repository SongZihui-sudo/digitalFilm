{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.mobile_optimizer import optimize_for_mobile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通道注意力机制 (Channel Attention Mechanism)\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class FilmStyleTransfer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FilmStyleTransfer, self).__init__()\n",
    "\n",
    "        # 定义卷积层\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = torch.nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = torch.nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7 = torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = torch.nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 定义激活函数\n",
    "        self.leakyrelu = torch.nn.LeakyReLU()\n",
    "        \n",
    "        # 定义BatchNorm层\n",
    "        self.bn1 = torch.nn.BatchNorm2d(32)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(128)\n",
    "        self.bn4 = torch.nn.BatchNorm2d(256)\n",
    "        self.bn5 = torch.nn.BatchNorm2d(128)\n",
    "        self.bn6 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn7 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # 注意力机制\n",
    "        self.ca2 = ChannelAttention(64)\n",
    "        self.ca3 = ChannelAttention(128)\n",
    "        self.ca4 = ChannelAttention(256)\n",
    "        self.ca5 = ChannelAttention(128)\n",
    "        self.ca6 = ChannelAttention(64)\n",
    "        self.ca7 = ChannelAttention(32)\n",
    "        \n",
    "        # 跳跃连接的卷积层\n",
    "        self.skip1 = torch.nn.Conv2d(32, 3, kernel_size=1, stride=1, padding=0)  # 将32通道映射到3通道\n",
    "        self.skip2 = torch.nn.Conv2d(64, 3, kernel_size=1, stride=1, padding=0)  # 将64通道映射到3通道\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = (self.leakyrelu(self.bn1(self.conv1(x))))\n",
    "        x2 = self.ca2(self.leakyrelu(self.bn2(self.conv2(x1))))\n",
    "        x3 = self.ca3(self.leakyrelu(self.bn3(self.conv3(x2))))\n",
    "        x4 = self.ca4(self.leakyrelu(self.bn4(self.conv4(x3))))\n",
    "        x5 = self.ca5(self.leakyrelu(self.bn5(self.conv5(x4))))\n",
    "        x6 = self.ca6(self.leakyrelu(self.bn6(self.conv6(x5))))\n",
    "        x7 = self.ca7(self.leakyrelu(self.bn7(self.conv7(x6))))\n",
    "        x8 = self.conv8(x7)\n",
    "        \n",
    "        # 跳跃连接\n",
    "        skip1 = self.skip1(x1)  # 将x1的32通道映射到3通道\n",
    "        skip2 = self.skip2(x2)  # 将x2的64通道映射到3通道\n",
    "        \n",
    "        # 合并跳跃连接和最终输出\n",
    "        output = x8 + skip1 + skip2\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_pre_train_model = FilmStyleTransfer()\n",
    "loss_function = torch.nn.SmoothL1Loss(reduction='mean')\n",
    "pre_train_pre_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./final_gold_200_training_500.pt\", map_location=device)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 恢复模型和优化器状态\n",
    "other_pre_train_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "other_pre_train_model = other_pre_train_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.rand(1, 3, 200, 320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_pre_train_model.eval()\n",
    "mobile_android = torch.jit.trace(other_pre_train_model, input_tensor)\n",
    "optimized_traced_model = optimize_for_mobile(mobile_android)\n",
    "optimized_traced_model.save(\"./android_kodak_gold_200.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digitalFilm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

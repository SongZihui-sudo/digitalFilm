{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePairDataset(Dataset):\n",
    "    def __init__(self, folder1, folder2, pairs, transform=None, enhance_transform_1 = None, \n",
    "                 enhance_transform_2 = None, enhance_transform_3 = None):\n",
    "        self.folder1 = folder1\n",
    "        self.folder2 = folder2\n",
    "        self.pairs = pairs\n",
    "        self.transform = transform\n",
    "        self.enhance_transform_1 = enhance_transform_1\n",
    "        self.enhance_transform_2 = enhance_transform_2\n",
    "        self.enhance_transform_3 = enhance_transform_3\n",
    "        self.image_pairs = self.read_image_pairs()\n",
    "\n",
    "    def read_image_pairs(self):\n",
    "      image_pairs = []\n",
    "      for image_pair in tqdm.tqdm(self.pairs):\n",
    "        img1_path = os.path.join(self.folder1, image_pair[0])\n",
    "        img2_path = os.path.join(self.folder2, image_pair[1])\n",
    "        img1 = Image.open(img1_path).convert(\"RGB\")\n",
    "        img2 = Image.open(img2_path).convert(\"RGB\")\n",
    "        img3 = img1\n",
    "        img4 = img2\n",
    "        img5 = img1\n",
    "        img6 = img2\n",
    "        img7 = img1\n",
    "        img8 = img2\n",
    "        if self.transform:\n",
    "            img1 = self.transform(img1)\n",
    "            img2 = self.transform(img2)\n",
    "        if self.enhance_transform_1:\n",
    "            img3 = self.enhance_transform_1(img3)\n",
    "            img4 = self.enhance_transform_1(img4)\n",
    "        if self.enhance_transform_2:\n",
    "            img5 = self.enhance_transform_2(img5)\n",
    "            img6 = self.enhance_transform_2(img6)\n",
    "        if self.enhance_transform_3:\n",
    "            img7 = self.enhance_transform_3(img7)\n",
    "            img8 = self.enhance_transform_3(img8)\n",
    "        image_pairs.append((img1, img2))\n",
    "        image_pairs.append((img3, img4))\n",
    "        image_pairs.append((img5, img6))\n",
    "        image_pairs.append((img7, img8))\n",
    "      return image_pairs\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      return self.image_pairs[idx][0], self.image_pairs[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to the folders\n",
    "digital_dir = \"D:/data/数码\"\n",
    "film_dir = \"D:/data/富士c200/胶片模拟/JPEG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1517\n",
      "1517\n"
     ]
    }
   ],
   "source": [
    "# Get the list of files in both folders\n",
    "digital = sorted(os.listdir(digital_dir))\n",
    "film = sorted(os.listdir(film_dir))\n",
    "\n",
    "print(len(digital))\n",
    "print(len(film))\n",
    "\n",
    "# Ensure the number of files match\n",
    "if len(digital) != len(film):\n",
    "    raise ValueError(\"The two folders must have the same number of images.\")\n",
    "\n",
    "# Create pairs of images (file1, file2)\n",
    "pairs = list(zip(digital, film))\n",
    "\n",
    "# Split into training and testing sets\n",
    "train_pairs, test_pairs = train_test_split(pairs, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations (if needed)\n",
    "transform = transforms.Compose([\n",
    "  transforms.Resize((200, 320)),\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "enhance_transform_1 = transforms.Compose([\n",
    "  transforms.RandomRotation(degrees=(-180, -180), expand=True),\n",
    "  transforms.Resize((200, 320)),\n",
    "  transforms.ToTensor(),\n",
    "])\n",
    "enhance_transform_2 = transforms.Compose([\n",
    "  transforms.CenterCrop(330),\n",
    "  transforms.Resize((200, 320)),\n",
    "  transforms.ToTensor(),\n",
    "])\n",
    "enhance_transform_3 = transforms.Compose([\n",
    "  transforms.RandomRotation(degrees=(-90, -90), expand=True),\n",
    "  transforms.Resize((200, 320)),\n",
    "  transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1213/1213 [04:15<00:00,  4.74it/s]\n",
      "100%|██████████| 304/304 [01:00<00:00,  5.01it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create datasets\n",
    "train_dataset = ImagePairDataset(digital_dir, film_dir, train_pairs, transform=transform, \n",
    "                                 enhance_transform_1=enhance_transform_1,\n",
    "                                 enhance_transform_2=enhance_transform_2,\n",
    "                                 enhance_transform_3 = enhance_transform_3)\n",
    "test_dataset = ImagePairDataset(digital_dir, film_dir, test_pairs, transform=transform, \n",
    "                                enhance_transform_1=enhance_transform_1,\n",
    "                                enhance_transform_2=enhance_transform_2,\n",
    "                                enhance_transform_3 = enhance_transform_3)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle=False, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 通道注意力机制 (Channel Attention Mechanism)\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super(ChannelAttention, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels // reduction, 1, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels // reduction, in_channels, 1, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        avg_out = self.fc(self.avg_pool(x))\n",
    "        max_out = self.fc(self.max_pool(x))\n",
    "        out = avg_out + max_out\n",
    "        return self.sigmoid(out)\n",
    "\n",
    "class FilmStyleTransfer(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FilmStyleTransfer, self).__init__()\n",
    "\n",
    "        # 定义卷积层\n",
    "        self.conv1 = torch.nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = torch.nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = torch.nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7 = torch.nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv8 = torch.nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1)\n",
    "        \n",
    "        # 定义激活函数\n",
    "        self.leakyrelu = torch.nn.LeakyReLU()\n",
    "        \n",
    "        # 定义BatchNorm层\n",
    "        self.bn1 = torch.nn.BatchNorm2d(32)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(128)\n",
    "        self.bn4 = torch.nn.BatchNorm2d(256)\n",
    "        self.bn5 = torch.nn.BatchNorm2d(128)\n",
    "        self.bn6 = torch.nn.BatchNorm2d(64)\n",
    "        self.bn7 = torch.nn.BatchNorm2d(32)\n",
    "\n",
    "        # 注意力机制\n",
    "        self.ca2 = ChannelAttention(64)\n",
    "        self.ca3 = ChannelAttention(128)\n",
    "        self.ca4 = ChannelAttention(256)\n",
    "        self.ca5 = ChannelAttention(128)\n",
    "        self.ca6 = ChannelAttention(64)\n",
    "        self.ca7 = ChannelAttention(32)\n",
    "        \n",
    "        # 跳跃连接的卷积层\n",
    "        self.skip1 = torch.nn.Conv2d(32, 3, kernel_size=1, stride=1, padding=0)  # 将32通道映射到3通道\n",
    "        self.skip2 = torch.nn.Conv2d(64, 3, kernel_size=1, stride=1, padding=0)  # 将64通道映射到3通道\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = (self.leakyrelu(self.bn1(self.conv1(x))))\n",
    "        x2 = self.ca2(self.leakyrelu(self.bn2(self.conv2(x1))))\n",
    "        x3 = self.ca3(self.leakyrelu(self.bn3(self.conv3(x2))))\n",
    "        x4 = self.ca4(self.leakyrelu(self.bn4(self.conv4(x3))))\n",
    "        x5 = self.ca5(self.leakyrelu(self.bn5(self.conv5(x4))))\n",
    "        x6 = self.ca6(self.leakyrelu(self.bn6(self.conv6(x5))))\n",
    "        x7 = self.ca7(self.leakyrelu(self.bn7(self.conv7(x6))))\n",
    "        x8 = self.conv8(x7)\n",
    "        \n",
    "        # 跳跃连接\n",
    "        skip1 = self.skip1(x1)  # 将x1的32通道映射到3通道\n",
    "        skip2 = self.skip2(x2)  # 将x2的64通道映射到3通道\n",
    "        \n",
    "        # 合并跳跃连接和最终输出\n",
    "        output = x8 + skip1 + skip2\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChannelStatLoss(nn.Module):\n",
    "    def forward(self, pred, target):\n",
    "        loss = 0.0\n",
    "        # 遍历RGB通道\n",
    "        for c in range(3):\n",
    "            pred_channel = pred[:, c, :, :]\n",
    "            target_channel = target[:, c, :, :]\n",
    "            \n",
    "            # 均值差异（L1）\n",
    "            loss += torch.abs(pred_channel.mean() - target_channel.mean())\n",
    "            # 方差差异（L1）\n",
    "            loss += torch.abs(pred_channel.var() - target_channel.var())\n",
    "        \n",
    "        lossrgb = loss + torch.nn.functional.l1_loss(pred, target)\n",
    "        \n",
    "        return lossrgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(target, prediction, max_pixel=1.0):\n",
    "    mse = torch.nn.functional.mse_loss(target, prediction)\n",
    "    if mse == 0:\n",
    "        return float('inf')  # 如果 MSE 为 0，意味着两图完全相同\n",
    "    return 20 * math.log10(max_pixel / math.sqrt(mse))\n",
    "\n",
    "def evaluate_psnr_generate(data_loader, model, max_pixel=1.0):\n",
    "    total_psnr = 0.0\n",
    "    num_images = 0\n",
    "\n",
    "    # 遍历数据集\n",
    "    for generated_images, original_images in data_loader:\n",
    "        # 确保输入输出图像在相同的设备上（例如：GPU）\n",
    "        original_images = original_images.to(device)\n",
    "        generated_images = generated_images.to(device)\n",
    "\n",
    "        # 计算每一对图像的 PSNR\n",
    "        for orig, gen in zip(original_images, generated_images):\n",
    "            orig = orig.unsqueeze(0).cuda()  # 增加批量维度\n",
    "            output = model(orig)\n",
    "            psnr_value = psnr(gen, output[0], max_pixel=max_pixel)\n",
    "            total_psnr += psnr_value\n",
    "            num_images += 1\n",
    "\n",
    "    # 计算整个数据集的平均 PSNR\n",
    "    avg_psnr = total_psnr / num_images if num_images > 0 else 0.0\n",
    "    return avg_psnr\n",
    "\n",
    "def evaluate_psnr_pre_train(data_loader, model, max_pixel=1.0):\n",
    "    total_psnr = 0.0\n",
    "    num_images = 0\n",
    "\n",
    "    # 遍历数据集\n",
    "    for generated_images, original_images in data_loader:\n",
    "        # 确保输入输出图像在相同的设备上（例如：GPU）\n",
    "        original_images = original_images.to(device)\n",
    "        generated_images = generated_images.to(device)\n",
    "\n",
    "        # 计算每一对图像的 PSNR\n",
    "        for orig, gen in zip(original_images, generated_images):\n",
    "            gen = gen.unsqueeze(0).cuda()  # 增加批量维度\n",
    "            output = model(gen)\n",
    "            psnr_value = psnr(orig, output[0], max_pixel=max_pixel)\n",
    "            total_psnr += psnr_value\n",
    "            num_images += 1\n",
    "\n",
    "    # 计算整个数据集的平均 PSNR\n",
    "    avg_psnr = total_psnr / num_images if num_images > 0 else 0.0\n",
    "    return avg_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_image(tensor):\n",
    "    \"\"\"将模型输出的张量转换为 PIL 图像\"\"\"\n",
    "    tensor = tensor.squeeze(0)  # 去掉 batch 维度\n",
    "    tensor = tensor.clamp(0, 1)  # 确保值在 [0, 1] 范围内\n",
    "    transform = transforms.ToPILImage()  # 转换为 PIL 图像\n",
    "    image = transform(tensor)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_train_model = FilmStyleTransfer()\n",
    "pre_train_model = pre_train_model.to(device)\n",
    "optimizer = optim.Adam(pre_train_model.parameters(), lr=0.0001)\n",
    "loss_function = torch.nn.SmoothL1Loss(reduction='mean')\n",
    "pre_train_pre_epochs = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./models/预训练/pre_train_gold_200_training_200.pt\")\n",
    "\n",
    "# 恢复模型和优化器状态\n",
    "pre_train_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "pre_train_model = pre_train_model.to(device)\n",
    "pre_train_model.eval()\n",
    "pre_train_pre_epochs = checkpoint['epoch']\n",
    "\n",
    "# 恢复训练状态\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条:  10%|█         | 100/1000 [13:08<2:00:56,  8.06s/it, loss=0.001]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 100 saved.\n",
      "Average PSNR for the dataset: 27.53 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条:  20%|██        | 200/1000 [26:40<1:45:14,  7.89s/it, loss=0.000676]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 200 saved.\n",
      "Average PSNR for the dataset: 29.94 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条:  30%|███       | 300/1000 [39:45<1:33:50,  8.04s/it, loss=0.000704]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 300 saved.\n",
      "Average PSNR for the dataset: 29.25 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条:  40%|████      | 400/1000 [53:14<1:18:36,  7.86s/it, loss=0.000637]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 400 saved.\n",
      "Average PSNR for the dataset: 30.80 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条:  50%|█████     | 500/1000 [1:06:40<1:07:13,  8.07s/it, loss=0.000564]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 500 saved.\n",
      "Average PSNR for the dataset: 31.34 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条:  60%|██████    | 600/1000 [1:20:03<53:09,  7.97s/it, loss=0.00039]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 600 saved.\n",
      "Average PSNR for the dataset: 30.78 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条:  70%|███████   | 700/1000 [1:33:15<40:00,  8.00s/it, loss=0.00119] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 700 saved.\n",
      "Average PSNR for the dataset: 30.64 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条:  80%|████████  | 800/1000 [1:46:43<26:50,  8.05s/it, loss=0.000424]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 800 saved.\n",
      "Average PSNR for the dataset: 31.15 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条:  90%|█████████ | 900/1000 [1:59:57<13:11,  7.92s/it, loss=0.0015]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 900 saved.\n",
      "Average PSNR for the dataset: 31.45 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条: 100%|██████████| 1000/1000 [2:13:13<00:00,  7.93s/it, loss=0.000685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: 1000 saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "进度条: 100%|██████████| 1000/1000 [2:13:16<00:00,  8.00s/it, loss=0.000685]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR for the dataset: 32.11 dB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "num_epochs = 1000\n",
    "psnr_list = []\n",
    "\n",
    "with tqdm.tqdm(total=num_epochs, desc=\"进度条\") as pbar:\n",
    "    for epoch in range(num_epochs):\n",
    "        pre_train_model.train()\n",
    "        for i, (img1, img2) in enumerate(train_loader):\n",
    "            img1, img2 = img1.cuda(), img2.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed = pre_train_model(img1)\n",
    "            loss = loss_function(reconstructed, img2)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            pbar.set_postfix(loss=loss.item())\n",
    "        pbar.update(1)\n",
    "        if not ((epoch + 1 + pre_train_pre_epochs) % (100)):\n",
    "            pre_train_model.eval()\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + pre_train_pre_epochs + 1,\n",
    "                'model_state_dict': pre_train_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "            }\n",
    "            torch.save(checkpoint, 'pre_train_gold_200_training_' + str(epoch + pre_train_pre_epochs + 1) + '.pt')\n",
    "            print(\"checkpoint: %s saved.\" % str(epoch + pre_train_pre_epochs + 1))\n",
    "            avg_psnr = evaluate_psnr_pre_train(test_loader, pre_train_model)\n",
    "            print(f'Average PSNR for the dataset: {avg_psnr:.2f} dB')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "digitalFilm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
